# Prometheus stack on k8s

We add the helm repository and install the `kube-prometheus-stack` chart:
```
$ helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
$ helm repo update
$ helm install monitoring prometheus-community/kube-prometheus-stack
$ helm install time-server-14-pralell
```

The k8s statistics is below:
```
$ kubectl get po,sts,svc,pvc,cm
NAME                                                         READY   STATUS    RESTARTS   AGE
pod/alertmanager-monitoring-kube-prometheus-alertmanager-0   2/2     Running   0          6m2s
pod/monitoring-grafana-5687c8b9fd-w759j                      2/2     Running   0          6m4s
pod/monitoring-kube-prometheus-operator-74fc8cdf87-7l2gc     1/1     Running   0          6m4s
pod/monitoring-kube-state-metrics-589766f6cb-qtvwn           1/1     Running   0          6m4s
pod/monitoring-prometheus-node-exporter-vtfmp                1/1     Running   0          6m4s
pod/prometheus-monitoring-kube-prometheus-prometheus-0       2/2     Running   0          6m2s
pod/time-server-14-0                                         1/1     Running   0          18s
pod/time-server-14-1                                         1/1     Running   0          18s
pod/time-server-14-2                                         1/1     Running   0          18s

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-monitoring-kube-prometheus-alertmanager   1/1     6m2s
statefulset.apps/prometheus-monitoring-kube-prometheus-prometheus       1/1     6m2s
statefulset.apps/time-server-14                                         3/3     18s

NAME                                              TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                      AGE
service/alertmanager-operated                     ClusterIP      None             <none>          9093/TCP,9094/TCP,9094/UDP   6m2s
service/kubernetes                                ClusterIP      10.96.0.1        <none>          443/TCP                      8d
service/monitoring-grafana                        ClusterIP      10.108.78.171    <none>          80/TCP                       6m4s
service/monitoring-kube-prometheus-alertmanager   ClusterIP      10.107.112.228   <none>          9093/TCP                     6m4s
service/monitoring-kube-prometheus-operator       ClusterIP      10.111.162.76    <none>          443/TCP                      6m4s
service/monitoring-kube-prometheus-prometheus     ClusterIP      10.102.21.173    <none>          9090/TCP                     6m4s
service/monitoring-kube-state-metrics             ClusterIP      10.104.176.168   <none>          8080/TCP                     6m4s
service/monitoring-prometheus-node-exporter       ClusterIP      10.104.33.160    <none>          9100/TCP                     6m4s
service/prometheus-operated                       ClusterIP      None             <none>          9090/TCP                     6m2s
service/time-server-14                            LoadBalancer   10.105.83.165    10.105.83.165   8080:32097/TCP               18s

NAME                                                                     DATA   AGE
configmap/kube-root-ca.crt                                               1      8d
configmap/monitoring-grafana                                             1      6m4s
configmap/monitoring-grafana-config-dashboards                           1      6m4s
configmap/monitoring-grafana-test                                        1      6m4s
configmap/monitoring-kube-prometheus-alertmanager-overview               1      6m4s
configmap/monitoring-kube-prometheus-apiserver                           1      6m4s
configmap/monitoring-kube-prometheus-cluster-total                       1      6m4s
configmap/monitoring-kube-prometheus-controller-manager                  1      6m4s
configmap/monitoring-kube-prometheus-etcd                                1      6m4s
configmap/monitoring-kube-prometheus-grafana-datasource                  1      6m4s
configmap/monitoring-kube-prometheus-k8s-coredns                         1      6m4s
configmap/monitoring-kube-prometheus-k8s-resources-cluster               1      6m4s
configmap/monitoring-kube-prometheus-k8s-resources-namespace             1      6m4s
configmap/monitoring-kube-prometheus-k8s-resources-node                  1      6m4s
configmap/monitoring-kube-prometheus-k8s-resources-pod                   1      6m4s
configmap/monitoring-kube-prometheus-k8s-resources-workload              1      6m4s
configmap/monitoring-kube-prometheus-k8s-resources-workloads-namespace   1      6m4s
configmap/monitoring-kube-prometheus-kubelet                             1      6m4s
configmap/monitoring-kube-prometheus-namespace-by-pod                    1      6m4s
configmap/monitoring-kube-prometheus-namespace-by-workload               1      6m4s
configmap/monitoring-kube-prometheus-node-cluster-rsrc-use               1      6m4s
configmap/monitoring-kube-prometheus-node-rsrc-use                       1      6m4s
configmap/monitoring-kube-prometheus-nodes                               1      6m4s
configmap/monitoring-kube-prometheus-persistentvolumesusage              1      6m4s
configmap/monitoring-kube-prometheus-pod-total                           1      6m4s
configmap/monitoring-kube-prometheus-prometheus                          1      6m4s
configmap/monitoring-kube-prometheus-proxy                               1      6m4s
configmap/monitoring-kube-prometheus-scheduler                           1      6m4s
configmap/monitoring-kube-prometheus-statefulset                         1      6m4s
configmap/monitoring-kube-prometheus-workload-total                      1      6m4s
configmap/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0   28     6m2s
configmap/server-user-data                                               1      18s
```

The abbreviations stand for the following:
* `po` - POds
* `sts` - STatefulSets
* `svc` - SerViCes
* `pvc` - PersistentVolumeClaims
* `cm` - ConfigMaps

This can be found out by running the following command: `kubectl api-resource | grep -E "po|sts|svc|pvc|cm"`.

## Components

### The Prometheus Operator

This component provides a framework that allows to easily deploy and manage prometheus on a kubernetes cluster: custom resources for prometheus, alertmanager and other services, for specifying persitance, retention policies and replicas.

This component is a base for the `prometheus-community/kube-prometheus-stack` chart.

### Highly available Prometheus

Prometheus is a metric collection/processing server with an ability to query metrics and generate alerts on certain events.

### Highly available Alertmanager

Alertmanager collects alerts from prometheus, filterns them and sends to other mediums like email.

### Prometheus node-exporter

node-exporter provides prometheus with metrics conserving node hardware.

### Prometheus Adapter for Kubernetes Metrics APIs

This component is a bridge between Kubernetes Metrics API and prometheus. It queries k8s and makes k8s metrics available within prometheus.

### kube-state-metrics

kube-state-metrics a little service that exposes an API to query k8s objects' states.

### Grafana

Grafana is a dashboard engine that is configured with lots and lots of dashboards rendering all of the data prometheus has gathered and is gathering.

## Quiz

To access grafana we need to use `admin` user and `prom-operator` as a password. The latter can be found out by running:
```
$ helm show values prometheus-community/kube-prometheus-stack
```

And navigating to `grafana.adminPassword` field.

> 1. Check how much CPU and Memory your StatefulSet is consuming.

Found in `General/Kubernetes/StatefulSets` dashboard. Value are:
* CPU: 0.00198
* Memory: 0.0672

> 2. Check which Pod is using CPU more than others and which is less in the default namespace.

Found in `General/Kubernetes/Compute Resources/Namespace (Pods)` dashboard with `default` namespace selected.

`prometheus-monitoring-kube-prometheus-prometheus-0` is the most CPU intensive pod peaking at 0.18 CPU usage. Our `time-server-14` doesn't consume CPU at all. Additionally there are `monitoring-kube-state-metrics-589766f6cb-qtvwn` and `monitoring-kube-state-metrics-589766f6cb-qtvwn` that consumed zero CPU also.

> 3. Check how much memory is used on your node, in % and mb.

Found in `General/Node Exporter/Nodes` dashboard. 4.5 GiB of memory used, which was 73.3%.

> 4. Check how many pods and containers actually ran by the Kubelet service.

Found in `General/Kubernetes/Kubelet` dashboard.
* Running pods: 36
* Running containers: 68

> 5. Check which Pod is using network more than others and which is less in the default namespace.

Found in `General/Kubernetes/Networking/Namespace (Pods)` dashboard.
* Most hungry (according to bytes received): `prometheus-monitoring-kube-prometheus-prometheus-0`
* Least hungry: our time server pods

> 6. Check how many alerts you have. Also you can see them in the Web UI by the `minikube service monitoring-kube-prometheus-alertmanager` command.

By accessing `monitoring-kube-prometheus-alertmanager` entry point (cluster IP with port from `kubectl get svc`) we can see that we have 6 categories of alerts and 9 alerts in total.

